---
    marp: true
    _theme: gaia
    paginate: true
    backgroundColor: #f5f5f5

    ---
# 論文概要

- 事前学習済み言語モデルを使用した多変量時系列予測手法の提案
- 少数のサンプルでも高い予測性能を発揮
- 実験結果からSOTAの性能を示す
- 異なるドメインの事前学習済みTransformerモデルでも時系列予測可能
---
# 事前学習済み言語モデルを用いた時系列予測のクロスドメイン知識転移

- 本論文の提案内容
    - few-shot learning、full data learning、zero-shot learningにおけるクロスドメイン知識転移
- 先行研究にはない貢献
    - 時系列データの多様性が異なるドメイン間での知識転移をより困難にしているため
- コンピュータビジョンドメインからの事前学習済みモデルの利用可能性も探索
---
# 論文概要

- 自然言語や画像データに事前学習されたtransformerモデルを、時間系列予測に転移学習する手法を提案
- Zero-Shot、Few-Shot、通常のサンプルサイズの条件下で評価
- 他の研究と比較して、優れた性能を発揮することが示されている
